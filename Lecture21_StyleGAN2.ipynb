{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_s8h-ilzHQc"
      },
      "source": [
        "# StyleGAN2\n",
        "\n",
        "Open in Colab: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/zlisto/natural_language_generation/blob/main/Fake_Faces_with_StyleGAN2.ipynb)\n",
        "\n",
        "\n",
        "\n",
        "This notebook demonstrates how to run NVIDIA's StyleGAN2 on Google Colab.\n",
        "Make sure to specify a GPU runtime.\n",
        "\n",
        "This notebook mainly adds a few convenience functions. \n",
        "\n",
        "For information on StyleGAN2, see:\n",
        "\n",
        "Paper: https://arxiv.org/abs/1812.04948\n",
        "\n",
        "Video: https://youtu.be/kSLJriaOumA\n",
        "\n",
        "Code: https://github.com/NVlabs/stylegan\n",
        "\n",
        "FFHQ: https://github.com/NVlabs/ffhq-dataset\n",
        "\n",
        "Mikael Christensen, 2019.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6Mv2KBQc1hT"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlIAue8Lc4FD"
      },
      "source": [
        "### Clone StyleGAN2 Repository\n",
        "\n",
        "We will need to make sure we have the proper version of TensorFlow.  We then clone StyleGAN2 from its GitHubg repository: https://github.com/NVlabs/stylegan2.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzDuIoMcqfBT"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# Download the code\n",
        "!git clone https://github.com/NVlabs/stylegan2.git\n",
        "%cd stylegan2\n",
        "!nvcc test_nvcc.cu -o test_nvcc -run\n",
        "\n",
        "print('Tensorflow version: {}'.format(tf.__version__) )\n",
        "!nvidia-smi -L\n",
        "print('GPU Identified at: {}'.format(tf.test.gpu_device_name()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRU8y_EPdQAI"
      },
      "source": [
        "### Import Packages\n",
        "\n",
        "Now we import all the necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moLYwC85czAy"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import re\n",
        "import sys\n",
        "from io import BytesIO\n",
        "import IPython.display\n",
        "import numpy as np\n",
        "from math import ceil\n",
        "from PIL import Image, ImageDraw\n",
        "import imageio\n",
        "\n",
        "import pretrained_networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-sB7w9HdVwn"
      },
      "source": [
        "### Choose StyleGAN Model\n",
        "\n",
        "We download the model of choice. A complete list of pretrained models is in the code below.  These models generate many types of objects:\n",
        "\n",
        "1. Faces\n",
        "\n",
        "2. Cars\n",
        "\n",
        "3. Horses\n",
        "\n",
        "4. Churches\n",
        "\n",
        "5. Cats\n",
        "\n",
        "Set `model_name` equal to the chosen model. I think `\"stylegan2-ffhq-config-f.pkl\"` is the best choice for face generation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwVXBFaSuoIU"
      },
      "outputs": [],
      "source": [
        "#Model Names\n",
        "# 1024×1024 faces\n",
        "# stylegan2-ffhq-config-a.pkl\n",
        "# stylegan2-ffhq-config-b.pkl\n",
        "# stylegan2-ffhq-config-c.pkl\n",
        "# stylegan2-ffhq-config-d.pkl\n",
        "# stylegan2-ffhq-config-e.pkl\n",
        "# stylegan2-ffhq-config-f.pkl\n",
        "\n",
        "# 512×384 cars\n",
        "# stylegan2-car-config-a.pkl\n",
        "# stylegan2-car-config-b.pkl\n",
        "# stylegan2-car-config-c.pkl\n",
        "# stylegan2-car-config-d.pkl\n",
        "# stylegan2-car-config-e.pkl\n",
        "# stylegan2-car-config-f.pkl\n",
        "\n",
        "# 256x256 horses\n",
        "# stylegan2-horse-config-a.pkl\n",
        "# stylegan2-horse-config-f.pkl\n",
        "\n",
        "# 256x256 churches\n",
        "# stylegan2-church-config-a.pkl\n",
        "# stylegan2-church-config-f.pkl\n",
        "\n",
        "# 256x256 cats\n",
        "# stylegan2-cat-config-f.pkl\n",
        "# stylegan2-cat-config-a.pkl\n",
        "\n",
        "model_name = \"stylegan2-ffhq-config-f.pkl\"\n",
        "\n",
        "network_pkl = f\"gdrive:networks/{model_name}\"\n",
        "\n",
        "print('Loading networks from \"%s\"...' % network_pkl)\n",
        "_G, _D, Gs = pretrained_networks.load_networks(network_pkl)\n",
        "noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-npMDtH9eK92"
      },
      "source": [
        "### Helper Functions\n",
        "\n",
        "The code below has a whole bunch of useful functions we will use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zxbhe4uLvF_a"
      },
      "outputs": [],
      "source": [
        "# Useful utility functions...\n",
        "\n",
        "# Generates a list of images, based on a list of latent vectors (Z), and a list (or a single constant) of truncation_psi's.\n",
        "def generate_images_in_w_space(dlatents, truncation_psi):\n",
        "    Gs_kwargs = dnnlib.EasyDict()\n",
        "    Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "    Gs_kwargs.randomize_noise = False\n",
        "    Gs_kwargs.truncation_psi = truncation_psi\n",
        "    dlatent_avg = Gs.get_var('dlatent_avg') # [component]\n",
        "\n",
        "    imgs = []\n",
        "    for row, dlatent in log_progress(enumerate(dlatents), name = \"Generating images\"):\n",
        "        #row_dlatents = (dlatent[np.newaxis] - dlatent_avg) * np.reshape(truncation_psi, [-1, 1, 1]) + dlatent_avg\n",
        "        dl = (dlatent-dlatent_avg)*truncation_psi   + dlatent_avg\n",
        "        row_images = Gs.components.synthesis.run(dl,  **Gs_kwargs)\n",
        "        imgs.append(PIL.Image.fromarray(row_images[0], 'RGB'))\n",
        "    return imgs       \n",
        "\n",
        "def generate_images(zs, truncation_psi):\n",
        "    Gs_kwargs = dnnlib.EasyDict()\n",
        "    Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "    Gs_kwargs.randomize_noise = False\n",
        "    if not isinstance(truncation_psi, list):\n",
        "        truncation_psi = [truncation_psi] * len(zs)\n",
        "        \n",
        "    imgs = []\n",
        "    for z_idx, z in log_progress(enumerate(zs), size = len(zs), name = \"Generating images\"):\n",
        "        Gs_kwargs.truncation_psi = truncation_psi[z_idx]\n",
        "        noise_rnd = np.random.RandomState(1) # fix noise\n",
        "        tflib.set_vars({var: noise_rnd.randn(*var.shape.as_list()) for var in noise_vars}) # [height, width]\n",
        "        images = Gs.run(z, None, **Gs_kwargs) # [minibatch, height, width, channel]\n",
        "        imgs.append(PIL.Image.fromarray(images[0], 'RGB'))\n",
        "    return imgs\n",
        "\n",
        "def generate_zs_from_seeds(seeds):\n",
        "    zs = []\n",
        "    for seed_idx, seed in enumerate(seeds):\n",
        "        rnd = np.random.RandomState(seed)\n",
        "        z = rnd.randn(1, *Gs.input_shape[1:]) # [minibatch, component]\n",
        "        zs.append(z)\n",
        "    return zs\n",
        "\n",
        "# Generates a list of images, based on a list of seed for latent vectors (Z), and a list (or a single constant) of truncation_psi's.\n",
        "def generate_images_from_seeds(seeds, truncation_psi):\n",
        "    return generate_images(generate_zs_from_seeds(seeds), truncation_psi)\n",
        "\n",
        "def saveImgs(imgs, location):\n",
        "  for idx, img in log_progress(enumerate(imgs), size = len(imgs), name=\"Saving images\"):\n",
        "    file = location+ str(idx) + \".png\"\n",
        "    img.save(file)\n",
        "\n",
        "def imshow_solo(a, format='png', jpeg_fallback=True,width = 128, height = 128):\n",
        "  a = np.asarray(a, dtype=np.uint8)\n",
        "  str_file = BytesIO()\n",
        "  PIL.Image.fromarray(a).save(str_file, format)\n",
        "  im_data = str_file.getvalue()\n",
        "  try:\n",
        "    disp = IPython.display.display(IPython.display.Image(im_data,width=width, height=height))\n",
        "  except IOError:\n",
        "    if jpeg_fallback and format != 'jpeg':\n",
        "      print ('Warning: image was too large to display in format \"{}\"; '\n",
        "             'trying jpeg instead.').format(format)\n",
        "      return imshow(a, format='jpeg')\n",
        "    else:\n",
        "      raise\n",
        "  return disp\n",
        "\n",
        "def imshow(a, format='png', jpeg_fallback=True):\n",
        "  a = np.asarray(a, dtype=np.uint8)\n",
        "  str_file = BytesIO()\n",
        "  PIL.Image.fromarray(a).save(str_file, format)\n",
        "  im_data = str_file.getvalue()\n",
        "  try:\n",
        "    disp = IPython.display.display(IPython.display.Image(im_data))\n",
        "  except IOError:\n",
        "    if jpeg_fallback and format != 'jpeg':\n",
        "      print ('Warning: image was too large to display in format \"{}\"; '\n",
        "             'trying jpeg instead.').format(format)\n",
        "      return imshow(a, format='jpeg')\n",
        "    else:\n",
        "      raise\n",
        "  return disp\n",
        "\n",
        "def showarray(a, fmt='png'):\n",
        "    a = np.uint8(a)\n",
        "    f = StringIO()\n",
        "    PIL.Image.fromarray(a).save(f, fmt)\n",
        "    IPython.display.display(IPython.display.Image(data=f.getvalue()))\n",
        "\n",
        "        \n",
        "def clamp(x, minimum, maximum):\n",
        "    return max(minimum, min(x, maximum))\n",
        "    \n",
        "def drawLatent(image,latents,x,y,x2,y2, color=(255,0,0,100)):\n",
        "  buffer = PIL.Image.new('RGBA', image.size, (0,0,0,0))\n",
        "   \n",
        "  draw = ImageDraw.Draw(buffer)\n",
        "  cy = (y+y2)/2\n",
        "  draw.rectangle([x,y,x2,y2],fill=(255,255,255,180), outline=(0,0,0,180))\n",
        "  for i in range(len(latents)):\n",
        "    mx = x + (x2-x)*(float(i)/len(latents))\n",
        "    h = (y2-y)*latents[i]*0.1\n",
        "    h = clamp(h,cy-y2,y2-cy)\n",
        "    draw.line((mx,cy,mx,cy+h),fill=color)\n",
        "  return PIL.Image.alpha_composite(image,buffer)\n",
        "             \n",
        "  \n",
        "def createImageGrid(images, scale=0.25, rows=1):\n",
        "   w,h = images[0].size\n",
        "   w = int(w*scale)\n",
        "   h = int(h*scale)\n",
        "   height = rows*h\n",
        "   cols = ceil(len(images) / rows)\n",
        "   width = cols*w\n",
        "   canvas = PIL.Image.new('RGBA', (width,height), 'white')\n",
        "   for i,img in enumerate(images):\n",
        "     img = img.resize((w,h), PIL.Image.ANTIALIAS)\n",
        "     canvas.paste(img, (w*(i % cols), h*(i // cols))) \n",
        "   return canvas\n",
        "\n",
        "def convertZtoW(latent, truncation_psi=0.7, truncation_cutoff=9):\n",
        "  dlatent = Gs.components.mapping.run(latent, None) # [seed, layer, component]\n",
        "  dlatent_avg = Gs.get_var('dlatent_avg') # [component]\n",
        "  for i in range(truncation_cutoff):\n",
        "    dlatent[0][i] = (dlatent[0][i]-dlatent_avg)*truncation_psi + dlatent_avg\n",
        "    \n",
        "  return dlatent\n",
        "\n",
        "def interpolate(zs, steps):\n",
        "   out = []\n",
        "   for i in range(len(zs)-1):\n",
        "    for index in range(steps):\n",
        "     fraction = index/float(steps) \n",
        "     out.append(zs[i+1]*fraction + zs[i]*(1-fraction))\n",
        "   return out\n",
        "\n",
        "# Taken from https://github.com/alexanderkuk/log-progress\n",
        "def log_progress(sequence, every=1, size=None, name='Items'):\n",
        "    from ipywidgets import IntProgress, HTML, VBox\n",
        "    from IPython.display import display\n",
        "\n",
        "    is_iterator = False\n",
        "    if size is None:\n",
        "        try:\n",
        "            size = len(sequence)\n",
        "        except TypeError:\n",
        "            is_iterator = True\n",
        "    if size is not None:\n",
        "        if every is None:\n",
        "            if size <= 200:\n",
        "                every = 1\n",
        "            else:\n",
        "                every = int(size / 200)     # every 0.5%\n",
        "    else:\n",
        "        assert every is not None, 'sequence is iterator, set every'\n",
        "\n",
        "    if is_iterator:\n",
        "        progress = IntProgress(min=0, max=1, value=1)\n",
        "        progress.bar_style = 'info'\n",
        "    else:\n",
        "        progress = IntProgress(min=0, max=size, value=0)\n",
        "    label = HTML()\n",
        "    box = VBox(children=[label, progress])\n",
        "    display(box)\n",
        "\n",
        "    index = 0\n",
        "    try:\n",
        "        for index, record in enumerate(sequence, 1):\n",
        "            if index == 1 or index % every == 0:\n",
        "                if is_iterator:\n",
        "                    label.value = '{name}: {index} / ?'.format(\n",
        "                        name=name,\n",
        "                        index=index\n",
        "                    )\n",
        "                else:\n",
        "                    progress.value = index\n",
        "                    label.value = u'{name}: {index} / {size}'.format(\n",
        "                        name=name,\n",
        "                        index=index,\n",
        "                        size=size\n",
        "                    )\n",
        "            yield record\n",
        "    except:\n",
        "        progress.bar_style = 'danger'\n",
        "        raise\n",
        "    else:\n",
        "        progress.bar_style = 'success'\n",
        "        progress.value = index\n",
        "        label.value = \"{name}: {index}\".format(\n",
        "            name=name,\n",
        "            index=str(index or '?')\n",
        "        )\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VM5wEi0eYBA"
      },
      "source": [
        "# Generate Fake Faces with StyleGAN2\n",
        "\n",
        "Set `seeds` equal to a list of integers.  From each seed a different face will be generated by StyleGAN2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQIhdSRcXC-Q"
      },
      "outputs": [],
      "source": [
        "# generate some random seeds\n",
        "seeds = [int(1e9), int(1e6), int(1e3)]\n",
        "print(f\"Seeds = {seeds}\")\n",
        "\n",
        "# show the seeds\n",
        "imgs =generate_images_from_seeds(seeds, 0.7)\n",
        "#imshow(createImageGrid(imgs, 0.7 , 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLLA0P0nkQIf"
      },
      "source": [
        "### View Individual Images\n",
        "\n",
        "Set `image_index` equal to the integer value of the image you want to view.  You can save this image by right-clicking on it and choosing **Save Image As...**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjI-X6gYkGfx"
      },
      "outputs": [],
      "source": [
        "for image_index in range(len(imgs)):\n",
        "  print(f\"Seed {seeds[image_index]}\")\n",
        "  imshow_solo(imgs[image_index],width = 256, height = 256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz9YCX-wfE5i"
      },
      "source": [
        "# Generate Interpolation of Faces with StyleGAN2 in Z-Space\n",
        "\n",
        "\n",
        "We generate random input vectors in z-space.  Pick two integers for the seed values `seed_A` and `seed_B`.  These will be used to generate the latent inputs to the StyleGAN2 model.  Then select `number_of_steps` for how many intermediate interpolated images you want to generate between the two seed images.\n",
        "\n",
        "The image arrays are saved in `imgs_z`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_aZvophLZQOw"
      },
      "outputs": [],
      "source": [
        "# Simple (Z) interpolation\n",
        "seed_A = 11\n",
        "seed_B = 12\n",
        "zs = generate_zs_from_seeds([seed_A , seed_B ])\n",
        "\n",
        "latent1 = zs[0]\n",
        "latent2 = zs[1]\n",
        "\n",
        "number_of_steps = 30\n",
        "\n",
        "print(f\"Interpolating in z-space from seed {seed_A} to {seed_B} with {number_of_steps} steps\")\n",
        "imgs_z = generate_images(interpolate([latent1,latent2],number_of_steps), 1.0)\n",
        "imshow(createImageGrid(imgs_z, 0.4 , 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIU5P6rkB8O4"
      },
      "source": [
        "### View Individual Images\n",
        "\n",
        "Set `image_index` equal to the integer value of the image you want to view.  You can save this image by right-clicking on it and choosing **Save Image As...**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQF6mRJoB4MV"
      },
      "outputs": [],
      "source": [
        "  image_index  = 15\n",
        "  print(f\"Z-space interpolated image {image_index}/{number_of_steps}\")\n",
        "  imshow_solo(imgs_z[image_index],width = 256, height = 256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gbd0ajNShn22"
      },
      "source": [
        "### Save Images to Movie\n",
        "\n",
        "We can save the images as a movie showing the face transforming from the intial face to the final face."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwXUbkVJXckp"
      },
      "outputs": [],
      "source": [
        "%mkdir out\n",
        "movieName_z = f'out/mov_z_space_{seed_A}_to_{seed_B}_{number_of_steps}_steps.mp4'\n",
        "\n",
        "with imageio.get_writer(movieName_z, mode='I') as writer:\n",
        "    for image in log_progress(list(imgs_z), name = \"Creating animation\"):\n",
        "        writer.append_data(np.array(image))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CE7-XxPGh0A9"
      },
      "source": [
        "# Generate Interpolation of Faces with StyleGAN2 in W-Space\n",
        "\n",
        "We generate random input vectors in w-space.  Pick two integers for the seed values `seed_A` and `seed_B`.  These will be used to generate the latent inputs to the StyleGAN2 model.  Then select `number_of_steps` for how many intermediate interpolated images you want to generate between the two seed images.\n",
        "\n",
        "The image arrays are saved in `imgs_w`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GofpNwi5aLl9"
      },
      "outputs": [],
      "source": [
        "seed_A = 11\n",
        "seed_B = 12\n",
        "\n",
        "zs = generate_zs_from_seeds([seed_A , seed_B ])\n",
        "\n",
        "# It seems my truncation_psi is slightly less efficient in W space - I probably introduced an error somewhere...\n",
        "\n",
        "dls = []\n",
        "for z in zs:\n",
        "  dls.append(convertZtoW(z ,truncation_psi=1.0))\n",
        "\n",
        "number_of_steps = 30\n",
        "\n",
        "print(f\"Interpolating in w-space from seed {seed_A} to {seed_B} with {number_of_steps} steps\")\n",
        "\n",
        "imgs_w = generate_images_in_w_space(interpolate(dls,number_of_steps), 1.0)\n",
        "imshow(createImageGrid(imgs_w, 0.4 , 3))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDIlETGNCdnr"
      },
      "source": [
        "### View Individual Images\n",
        "\n",
        "Set `image_index` equal to the integer value of the image you want to view.  You can save this image by right-clicking on it and choosing **Save Image As...**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJPgUoCpCdxM"
      },
      "outputs": [],
      "source": [
        "  image_index  = 15\n",
        "  print(f\"W-space interpolated image {image_index}/{number_of_steps}\")\n",
        "  imshow_solo(imgs_w[image_index],width = 256, height = 256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84DB0oNrlGxe"
      },
      "source": [
        "### Save Images to Movie\n",
        "\n",
        "We can save the images as a movie showing the face transforming from the intial face to the final face."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ors-HvLwgrsv"
      },
      "outputs": [],
      "source": [
        "%mkdir out\n",
        "movieName_w = f'out/mov_w_space_{seed_A}_to_{seed_B}_{number_of_steps}_steps.mp4'\n",
        "\n",
        "with imageio.get_writer(movieName_w, mode='I') as writer:\n",
        "    for image in log_progress(list(imgs_w), name = \"Creating animation\"):\n",
        "        writer.append_data(np.array(image))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH_GuDp-PX6S"
      },
      "source": [
        "# Tuning the Face in W-Space\n",
        "\n",
        "We can adjust the input in W-space to have more control over the face.  The W-space noise has shape (1, 18, 512).  The 512 is the dimension of the noise, and there are 18 layers in the  synthesis network.  We will add a constant to layer 0 and see how the base image is changed.  Choose a positive integer for `seed_A` to get a base image, then choose the values you want for the layer with the array `layer_values`.  The values should be between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNkvP-JPPX6S"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "layer_values = np.arange(0,0.4,0.05)\n",
        "seed_A = 1703186094\n",
        "layer = 0\n",
        "\n",
        "zs = generate_zs_from_seeds([seed_A , 1 ])\n",
        "\n",
        "dls = []\n",
        "for z in zs:\n",
        "  dls.append(convertZtoW(z ,truncation_psi=1.0))\n",
        "\n",
        "number_of_steps = 30\n",
        "wint = interpolate(dls,number_of_steps)\n",
        "s = wint[0].shape\n",
        "slayer = wint[0][:,1,:].shape\n",
        "nlayers = slayer[1]  #number of layers\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "imgs_w = generate_images_in_w_space(wint[0:1], 1.0)\n",
        "plt.imshow(imgs_w[0])\n",
        "plt.axis('off')\n",
        "plt.title(f\"Base image\")\n",
        "plt.show()\n",
        "count = 0\n",
        "for layer_value in layer_values:\n",
        "  w0 = wint\n",
        "  w0[layer] =  w0[layer]+layer_value * np.ones(s) \n",
        "  imgs_w = generate_images_in_w_space(w0[0:1], 1.0)\n",
        "  plt.imshow(imgs_w[0])\n",
        "  plt.axis('off')\n",
        "  plt.title(f\"Tune layer {layer} by {layer_value}\")\n",
        "  plt.show()\n",
        "  count+=1\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "NlIAue8Lc4FD"
      ],
      "name": "Fake Faces with StyleGAN2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}