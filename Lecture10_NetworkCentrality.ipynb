{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 10 - Network Centrality\n",
    "\n",
    "In this notebook we will learn how to calculate network centralities using the `networx` package.  For a complete list of network centralities that can be calculated you can look here: https://networkx.org/documentation/stable/reference/algorithms/centrality.html\n",
    "\n",
    "In addition, we will create interactive visualizations of the networks and make the centrality information visible in the node size and color.  \n",
    "\n",
    "Our example network will be a Twitter follower network.\n",
    "\n",
    "Below is the overview of this notebook.\n",
    "\n",
    "\n",
    "<ol type = 1>\n",
    "    <li> Data processing</li>\n",
    "        <ol type = a>\n",
    "            <li> Load follower network</li>\n",
    "        </ol>\n",
    "    <li> Calculate Network Centralities</li>\n",
    "        <ol type = a>\n",
    "            <li> Out-/in-degree centrality</li>\n",
    "            <li> Closeness centrality</li>\n",
    "            <li> Betweenness centrality</li>\n",
    "            <li> Eigenvector centrality</li>\n",
    "        </ol>\n",
    "\n",
    "   <li>Plot centralities</li>\n",
    "\n",
    "   <li> Network Visualization </li>\n",
    "        <ol type = a>\n",
    "            <li> Draw static visualization with nodes sized by centrality</li>\n",
    "            <li> Interactive visualization  with nodes sized by centrality</li>\n",
    "       </ol>\n",
    "    <li> Retweet Network Example </li>\n",
    "</ol>\n",
    "\n",
    "This notebook can be opened in Colab \n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/zlisto/social_media_analytics/blob/main/Lecture10_NetworkCentrality.ipynb)\n",
    "\n",
    "Before starting, select \"Runtime->Factory reset runtime\" to start with your directories and environment in the base state.\n",
    "\n",
    "If you want to save changes to the notebook, select \"File->Save a copy in Drive\" from the top menu in Colab.  This will save the notebook in your Google Drive.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clones, installs, and imports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone GitHub Repository\n",
    "This will clone the repository to your machine.  This includes the code and data files.  Then change into the directory of the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/zlisto/social_media_analytics\n",
    "\n",
    "import os\n",
    "os.chdir(\"social_media_analytics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Requirements \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "from bokeh.plotting  import show\n",
    "from bokeh.models import HoverTool\n",
    "hv.extension('bokeh')\n",
    "\n",
    "defaults = dict(width=800, height=800)\n",
    "hv.opts.defaults(opts.EdgePaths(**defaults), opts.Graph(**defaults), opts.Nodes(**defaults))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Follower Network\n",
    "\n",
    "The follower network is saved in a pickle file as a networkx object.  We load it using the `read_gpickle` function.  We can check how many nodes and edges in the network using the `number_of_nodes` and `number_of_edges` functions, respectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename of follower network\n",
    "fname_following = \"data/friends_network_JoeBiden.pickle\"\n",
    "\n",
    "G = nx.read_gpickle(fname_following)\n",
    "\n",
    "\n",
    "nv = G.number_of_nodes()\n",
    "ne = G.number_of_edges()\n",
    "print(f\"Network has {nv} nodes and {ne} edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Centralities\n",
    "\n",
    "There are a variety of network centrality functions we can use in networkx.  We will use several here.  We need to be careful with closeness and eigenvector centrality, as their definition of an edge is the reverse of our convention for social networks.\n",
    "\n",
    "1. `Din` = In-degree centrality (networkx divides the in-degree by `nv`-1 so the maximum value =1)\n",
    "\n",
    "2. `Dout` = Out-degree (networkx divides the out-degree by `nv`-1 so the maximum value =1)\n",
    "\n",
    "3. `CC` = Closeness centrality (we need to reverse edges of `G` to match networkx convention using the `reverse()` function)\n",
    "\n",
    "4. `BC` = Betweenness centrality (making the network undirected makes this work better)\n",
    "\n",
    "5. `EC` = Eigenvector centrality (we need to reverse edges of `G` to match networkx convention  using the `reverse()` function)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Din = nx.in_degree_centrality(G)\n",
    "Dout = nx.out_degree_centrality(G)\n",
    "CC = nx.closeness_centrality(G.reverse())  #reverse edges to match networx convention\n",
    "BC = nx.betweenness_centrality(G.to_undirected())\n",
    "EC = nx.eigenvector_centrality(G.reverse())  #reverse edges to match networx convention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert centralities into a dataframe\n",
    "\n",
    "The centralities calculated by networkx are returned as a *dictionary*.  A dictionary stores data as (key,value) pairs.  To access a value for a key **key** from a dictionary **Dic** you write:  `value = Dic[key]`.\n",
    "\n",
    "We will convert the dictionaries into lists.  We do this using a `for` loop that goes through every single key (which is a screen name) in the dictionaries, gets the corresponding centrality values, and creates a dictionary of the centralties for this screen name.  Then we append this dictionary to a list called `dictionary_list`.  Then we convert this list of dictionaries into a dataframe with the `DataFrame` command.  The resulting centralties dataframe is called `df_centrality`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For plotting, we combine all the centrality dictionaries into a dataframe\n",
    "dictionary_list = []\n",
    "for screen_name in Din.keys():\n",
    "    row = {'screen_name':screen_name,\n",
    "          'in_degree_centrality':Din[screen_name],\n",
    "          'out_degree_centrality':Dout[screen_name],\n",
    "          'closeness_centrality':CC[screen_name],\n",
    "          'betweenness_centrality':BC[screen_name],\n",
    "          'eigenvector_centrality':EC[screen_name]}\n",
    "    dictionary_list.append(row)\n",
    "df_centrality = pd.DataFrame(dictionary_list)\n",
    "\n",
    "df_centrality.sort_values(by = ['out_degree_centrality'],ascending = False).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot top centralities\n",
    "\n",
    "We will sort the top centralities descending order.  To make one big figure we use the subplot function.\n",
    "\n",
    "To make our code more efficient, we create a list `Centrality` that contains the name of each column of `df_centrality` that corresponds to a centrality.  Then we run a `for` loop over the centralties in this list, and make a bar plot of the top `kmax` values.  We make subplots for each centrality in one big figure.  There are many plot commands used here to make the figure look nice.  Have a look at them to see what they do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Centrality_names = df_centrality.columns.tolist()[1:]\n",
    "kmax = 10  #show top kmax users\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (20,14))\n",
    "\n",
    "for count,centrality_name in enumerate(Centrality_names):    \n",
    "    df_plot = df_centrality.sort_values(by=[centrality_name],ascending=False)  #sort dataframe by centrality value\n",
    "    plt.subplot(3,2,count+1) #make a 2 x 3 subplot, plot in box cnt+1\n",
    "    \n",
    "    ax = sns.barplot(data=df_plot[0:kmax], x='screen_name', y=centrality_name)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(),rotation = 90)\n",
    "    plt.xticks(fontsize = 14)\n",
    "    plt.yticks(fontsize = 14)\n",
    "    plt.ylabel(f\"{centrality_name}\",fontsize = 18)\n",
    "    plt.xlabel('Screen name',fontsize = 18)    \n",
    "    plt.grid()\n",
    "\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=0.75)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Visualization\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Layout\n",
    "First we calculate the node layout using the `kamada_kawai_layout` method (we will learn about this later).  We also define some properties of the network drawing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.kamada_kawai_layout(G)  #position of each node in the network\n",
    "\n",
    "\n",
    "node_color = 'red'\n",
    "edge_color = 'purple'\n",
    "background_color = 'black'\n",
    "edge_width = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Size Proportional to Centrality\n",
    "\n",
    "Then we make the node size proportional to different centrality values.  The `Centrality` variable is a list with the values of the chosen centrality from `df_centrality`.  The list `node_size_centrality` has the node sizes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "size_min = 1\n",
    "size_max = 1000\n",
    "\n",
    "#define parameters for linear interpolation of node size from out-degree\n",
    "Centrality = df_centrality['betweenness_centrality'].tolist()\n",
    "\n",
    "\n",
    "dmax = max(Centrality)\n",
    "dmin = min(Centrality)\n",
    "slope = (size_max-size_min)/(dmax-dmin)\n",
    "intercept = size_min-slope*dmin \n",
    "\n",
    "#Go through each node and calculate its size\n",
    "node_size_centrality = [c*slope+intercept  for c in Centrality ]    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw Network\n",
    "\n",
    "In the `draw` function, set the parameter `with_labels=True`and you can add labels of the nodes to the plot.  Use the parameter `font_color` to choose the font color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw the network, with labels    \n",
    "fig = plt.figure(figsize=(8,8))\n",
    "nx.draw(G, pos, node_color = node_color, width= edge_width,\n",
    "        edge_color=edge_color,node_size=node_size_centrality,\n",
    "       with_labels=True,font_color = 'white')\n",
    "fig.set_facecolor(background_color)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Network Visualization\n",
    "\n",
    "We will visualize the network using the *holoviews* package, which creates an interactive plot of the network.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Network Data\n",
    "First we need to\n",
    "add some node attributes to the networkx object `G` so we can display these values in the plot.  We need to save the values as strings to make them appear in the plot (it's weird, I know)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_size = 30\n",
    "pos = nx.kamada_kawai_layout(G)  #position of each node in the network\n",
    "\n",
    "for cnt,v in enumerate(G.nodes()):\n",
    "    dout = df_centrality.out_degree_centrality[df_centrality.screen_name==v].values[0]\n",
    "    din = df_centrality.in_degree_centrality[df_centrality.screen_name==v].values[0]\n",
    "    cc = df_centrality.closeness_centrality[df_centrality.screen_name==v].values[0]\n",
    "    bc = df_centrality.betweenness_centrality[df_centrality.screen_name==v].values[0]\n",
    "    ec = df_centrality.eigenvector_centrality[df_centrality.screen_name==v].values[0]\n",
    "\n",
    "    node_size = node_size\n",
    "    G.nodes[v]['out_degree_centrality'] = f\"{dout:.2f}\"\n",
    "    G.nodes[v]['in_degree_centrality'] =f\"{din:.2f}\"\n",
    "    G.nodes[v]['closeness_centrality'] = f\"{cc:.2}\"\n",
    "    G.nodes[v]['betweenness_centrality'] = f\"{bc:.2}\"\n",
    "    G.nodes[v]['eigenvector_centrality'] = f\"{ec:.2}\"\n",
    "    G.nodes[v][\"node_size\"] = node_size\n",
    "    G.nodes[v]['screen_name'] = v\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Holoviews interactive visualization\n",
    "\n",
    "We first define `tooltips` as a list of values and their names we want to display when \n",
    "we hover over a node.  Then we define `hover` as a HoverTool that displays\n",
    "the node information in `tooltips`.  Finally, we define `graph` as the network visualization\n",
    "object.  There are many self-explanatory fields here we can play with.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tooltips = [\n",
    "    ('Screen name','@screen_name'),\n",
    "    (\"Node size\",\"@node_size\"),\n",
    "    (\"Out-degree\",\"@out_degree_centrality\"),\n",
    "    (\"In-degree\",\"@in_degree_centrality\"),\n",
    "    (\"Closeness\",\"@closeness_centrality\"),\n",
    "    (\"Betweenness\",\"@betweenness_centrality\"),\n",
    "    (\"Eigenvector\",\"@eigenvector_centrality\"),\n",
    "\n",
    "    \n",
    "]\n",
    "hover = HoverTool(tooltips=tooltips)\n",
    "\n",
    "graph = hv.Graph.from_networkx(G, pos).opts(height=800, width=800, tools=[hover],node_size = hv.dim(\"node_size\"), \n",
    "                                    node_line_color='black', edge_line_color = 'purple',bgcolor='black',\n",
    "                                    node_hover_fill_color = 'red').relabel('Following network')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Network Visualization\n",
    "\n",
    "To create the visualization, just type `graph`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize network with nodes sized by a centrality\n",
    "\n",
    "We will do a linear interpolation of the node size based on a centrality measure.  We choose the \n",
    "`centrality_name` from our dataframe columns, and the `size_min` and `size_max` of the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the centrality to use for sizing, and get the min and max values\n",
    "centrality_name = 'closeness_centrality'\n",
    "\n",
    "#choose the minimum and maximum size for the nodes\n",
    "size_min = 10\n",
    "size_max  = 50\n",
    "\n",
    "#Find the minimum and maximum values for the centrality\n",
    "dmax = df_centrality[centrality_name].max()\n",
    "dmin = df_centrality[centrality_name].min()\n",
    "\n",
    "#calculate slope and intercept for linear interpolation of node size\n",
    "slope = (size_max-size_min)/(dmax-dmin)\n",
    "intercept = size_min-slope*dmin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.kamada_kawai_layout(G)  #position of each node in the network\n",
    "\n",
    "for v in G.nodes():\n",
    "    centrality =df_centrality[centrality_name][df_centrality.screen_name==v].values[0]\n",
    "    \n",
    "    node_size = centrality*slope+intercept  \n",
    "    G.nodes[v][\"node_size\"] = node_size\n",
    "    G.nodes[v]['screen_name'] = v\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_str = f'Following network, node size = {centrality_name}'\n",
    "tooltips = [\n",
    "    ('Screen name','@screen_name'),\n",
    "    (\"Node size\",\"@node_size\")  \n",
    "]\n",
    "hover = HoverTool(tooltips=tooltips)\n",
    "\n",
    "graph = hv.Graph.from_networkx(G, pos).opts(height=800, width=800, tools=[hover],\n",
    "                                            node_size = hv.dim(\"node_size\"), \n",
    "                                    node_line_color='black', \n",
    "                                            edge_line_color = 'purple',\n",
    "                                            bgcolor='black',\n",
    "                                    node_hover_fill_color = 'red').relabel(title_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retweet Network\n",
    "\n",
    "Now we will calculate centralities for a retweet network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename of retweet network\n",
    "fname_rt = \"data/nbaallstar_interaction_network.pickle\"\n",
    "\n",
    "Grt = nx.read_gpickle(fname_rt)\n",
    "\n",
    "\n",
    "nv = Grt.number_of_nodes()\n",
    "ne = Grt.number_of_edges()\n",
    "print(f\"Retweet network has {nv} nodes and {ne} edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Centralities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "Din = nx.in_degree_centrality(Grt)\n",
    "Dout = nx.out_degree_centrality(Grt)\n",
    "CC = nx.closeness_centrality(Grt.reverse())  #reverse edges to match networx convention\n",
    "BC = nx.betweenness_centrality(Grt.to_undirected())\n",
    "EC = nx.eigenvector_centrality(Grt.reverse())  #reverse edges to match networx convention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Centralities Into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For plotting, we combine all the centrality dictionaries into a dataframe\n",
    "dictionary_list = []\n",
    "for user_id in Din.keys():\n",
    "    screen_name = Grt.nodes[user_id]['username']\n",
    "    row = {'user_id':user_id,\n",
    "           'screen_name':screen_name,           \n",
    "          'in_degree_centrality':Din[user_id],\n",
    "          'out_degree_centrality':Dout[user_id],\n",
    "          'closeness_centrality':CC[user_id],\n",
    "          'betweenness_centrality':BC[user_id],\n",
    "          'eigenvector_centrality':EC[user_id]}\n",
    "    dictionary_list.append(row)\n",
    "df_centrality = pd.DataFrame(dictionary_list)\n",
    "\n",
    "df_centrality.sort_values(by = ['out_degree_centrality'],ascending = False).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Top Centralities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Centrality_names = df_centrality.columns.tolist()[2:]\n",
    "kmax = 10  #show top kmax users\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (20,14))\n",
    "\n",
    "for count,centrality_name in enumerate(Centrality_names):    \n",
    "    df_plot = df_centrality.sort_values(by=[centrality_name],ascending=False)  #sort dataframe by centrality value\n",
    "    plt.subplot(3,2,count+1) #make a 2 x 3 subplot, plot in box cnt+1\n",
    "    \n",
    "    ax = sns.barplot(data=df_plot[0:kmax], x='screen_name', y=centrality_name)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(),rotation = 90)\n",
    "    plt.xticks(fontsize = 14)\n",
    "    plt.yticks(fontsize = 14)\n",
    "    plt.ylabel(f\"{centrality_name}\",fontsize = 18)\n",
    "    plt.xlabel('Screen name',fontsize = 18)    \n",
    "    plt.grid()\n",
    "\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=0.75)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw Network\n",
    "\n",
    "The retweet network is rather large, so to draw it, we will only keep nodes with at least one neighbor.  The we created a subgraph `G1` that is the original graph, but only with the nodes we want to keep.  We do this using the `subgraph` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv = Grt.number_of_nodes()\n",
    "nodes_draw = df_centrality.user_id[df_centrality.out_degree_centrality*(nv-1)>=1].tolist()\n",
    "print(f\"Smaller network has {len(nodes_draw)} nodes\")\n",
    "\n",
    "G1 = Grt.subgraph(nodes_draw)\n",
    "nv1 = G1.number_of_nodes()\n",
    "ne1 = G1.number_of_edges()\n",
    "print(f\"Retweet sub-network has {nv1} nodes and {ne1} edges\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw Network, Size Nodes by Centrality\n",
    "\n",
    "We can draw the retweet sub-network with nodes sized by a centrality, as we did before.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.kamada_kawai_layout(G1)  #position of each node in the network\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the centrality to use for sizing, and get the min and max values\n",
    "centrality_name = 'out_degree_centrality'\n",
    "\n",
    "#choose the minimum and maximum size for the nodes\n",
    "size_min = 10\n",
    "size_max  = 50\n",
    "\n",
    "#Find the minimum and maximum values for the centrality\n",
    "dmax = df_centrality[centrality_name].max()\n",
    "dmin = df_centrality[centrality_name].min()\n",
    "\n",
    "#calculate slope and intercept for linear interpolation of node size\n",
    "slope = (size_max-size_min)/(dmax-dmin)\n",
    "intercept = size_min-slope*dmin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cnt,v in enumerate(G1.nodes()):\n",
    "    dout = df_centrality[centrality_name][df_centrality.user_id==v].values[0]\n",
    "    node_size = dout*slope+intercept  \n",
    "    G1.nodes[v][centrality_name] = f\"{dout:.4f}\"\n",
    "    G1.nodes[v][\"node_size\"] = node_size\n",
    "    G1.nodes[v]['screen_name'] = df_centrality.screen_name[df_centrality.user_id==v].values[0]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_str = f\"Retweet Network, Node Size = {centrality_name}\"\n",
    "tooltips = [\n",
    "    ('Screen name','@screen_name'),\n",
    "    (centrality_name,f\"@{centrality_name}\")\n",
    "]\n",
    "hover = HoverTool(tooltips=tooltips)\n",
    "\n",
    "graph = hv.Graph.from_networkx(G1, pos).opts(height=800, width=800, \n",
    "                                             tools=[hover],\n",
    "                                             node_size = hv.dim(\"node_size\"), \n",
    "                                    node_line_color='black', \n",
    "                                             edge_line_color = 'purple',\n",
    "                                             bgcolor='black',\n",
    "                                    node_hover_fill_color = 'red').relabel(title_str)\n",
    "\n",
    "\n",
    "#to show the network, just type graph\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
